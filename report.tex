% ----------
% A LaTeX template for course project reports
% 
% This template is modified from "Tech Report ala MIT AI Lab (1981)"
% 
% ----------
\documentclass[12pt, letterpaper, twoside]{article}
\usepackage{geometry}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[runin]{abstract}
\usepackage{titling}
\usepackage{booktabs}
\usepackage{fancyhdr}
\usepackage{helvet}
\usepackage{csquotes}
\usepackage{graphicx}
\usepackage{blindtext}
\usepackage{parskip}
\usepackage{etoolbox}
\usepackage{hyperref}

\graphicspath{ {./resources/report_pics/} }


\input{preamble.tex}

% ----------
% Variables
% ----------

\title{\textbf{Helping Municipalities Maintain Roads by Locating Defects Using Computer Vision}} % Full title of your tech report
\runningtitle{Detecting Road Defects Using Computer Vision} % Short title
\author{Samuel Bazinet} % Full list of authors
\runningauthor{Samuel Bazinet} % Short list of authors
\affiliation{Ontario Tech University} % Affiliation e.g. University or Company
\department{Faculty of Science, Computer Science} % Department or Office
\memoid{Project} % Project group ID that were shared with the class earlier.
\theyear{2024} % year of the tech report
\mydate{April 5, 2024} %the date


% ----------
% actual document
% ----------
\begin{document}
\maketitle

\begin{abstract}
    \noindent
    
    In a world where efficiency is more important than ever and with roads being built all the time,
    finding road defects needs to be as automated as possible to maintain a good driving experience for all citizens. 
    With computers getting faster by the year, 
    we can use this newfound ability to use them to help us automatically find defects such as potholes and cracks without human intervention.
    This paper looks over how we can setup such a system, 
    including finding an algorithm to find potential defects, 
    as well as training a machine learning model to differentiate between the types of defects.

    % Uncomment the following to add keywords as needed
    \keywords{Computer Vision, Infrastructure}
\end{abstract}

\vspace{2.5cm}

{\footnotesize
    \noindent
    The code used for this project can be found at: \url{https://github.com/samuel-bazinet/cv_project}
}

\thispagestyle{firstpage}

\pagebreak

% ----------
% End of first page
% ----------

\newgeometry{} % Redefine geometries (normal margins)

\section{Introduction}\label{sec:intro}

This course on computer vision started with a lab where stop signs had to be identified on an image. 
This was relatively simple as stop signs are standardized so they can be easily identified. 
Unfortunately, the same cannot be said for road defects. 
We cannot simply use a single default template and expect to get a substantial true match rate. 
This means that a substantial amount of work needs to take place in order to be able to outline the potential defects on the road.
This paper will go over the efforts required to get a relatively competent model to detect defects on an image of a road. 

\section{Methodology}\label{sec:meth}

Detecting defects on a road is a somewhat complex procedure involving many steps to get the model going. 
As we are trying to find cracks and potholes, we cannot use simple pattern matching as they very a lot in size, color, and pattern.
We need a machine learning model for this.
To achieve the model, a dataset will need to be created, then the model will be trained, before being used to highlight the defects on images.

\subsection{Finding Potential Defects}\label{sec:meth:1}

The first part of finding defects on road is to scan the image for potential defects. 
Cracks and potholes tend to be very well defined on roads, meaning that Canny edge detection is great way to find them.
But since roads can contain many edges, a blurring filter is ran beforehands to reduce the noise in the resulting edges.
Then, the program scans the image and groups adjacent edges together into their own objects so that we can extract the potential defects as their own images for later usage.
To make this easier, a dataclass called `Defect' was created.
This dataclass contains the coordinates of the corners of the area containing all the edges, as well as a list of pixels of where the edges were detected.
This class has a few helepr methods to merge potential defects contained within each other as the assumption was made that they would be part of the same defect.
It also has a method to ``recenter'' itself around the densest collection of edges for the purpose of training the model with evenly sized images.
50 images of damaged roads were ran through this ``potential defect extractor'' to collect hundreds of potential defects that will be used for training the model that will be used to detect the real defects.
\hyperref[app:train_data]{A subset of those pictures.}

\subsection{Training a Model to Classify the Defects}

There are 3 classes that will be used by the model: crack, pothole, and non-defect. 
To train the model, the images of the potential defects generated by the last step have been manually classified into 3 folders, one for each class.
Keras and TensorFlow were used to train the model as they were easy to use and have plenty of online resources for extra help.
The model startes by rescaling the data from a 255 base to 1 base so that it is faster to work on.
The model then performs a 2D convolution with 16 3$\times$3 filters, which are activated by ReLU\@.
It then goes through a max pooling layer with a 2$\times$2 window and a stride of 2.
There is another 2D convulution but with 32 filters, again activated by ReLU\@.
There is then a flatening layer to convert the data into a 1D vector.
To help fight overfitting, there is a dropout layer to drop 30\% of the input units.
Finally, there is a dense layer with 512 units activated by ReLU\@.
The model then goes through a final dense layer to link up to the number of classes. 
The data was augmenting using the Keras sequential augmenter, where the data set had images copied with different rotation and zoom levels.
This is quite useful as generating more images for training is very time consuming.
The model was trained over 100 epochs, where the training accuracy went from low 30\% to around 80\%
and the validation accuracy reached 70\% \hyperref[app:model_plot]{(see plot)}.
The model was saved for access by the actual defect identifier.

\subsection{Applying the model to potential defects and highlighting them on an image}

Using the same method as defined in \hyperref[sec:meth:1]{Section 2.1}, potential defects are found on the target images.
The model is then loaded into the Jupyter notebook and the potential defects are passed through it, where the predictions are obtained.
Using the prediction from the model, we draw a red line around predicted potholes, and a green line around predicted cracks.
Non defects are not highlighted.
This results into an image where the defects are highlighted so that the target audience will be able to easily see the work that needs to be done.

\section{Results}\label{sec:resu}

The model was tested on \hyperref[app:result_image]{a few pictures} with mixed results. 
The model is somewhat competent at identifying potholes and cracks, but it often mislabels them and misses quite a few defects as well.
It sometimes falsely labels non defects as defects, 
which is expected from a low accuracy model but is not desirable. 
It is quite sensitive to the resolution of the images and the low validation accuracy is made quite apparent.

\section{Discussion and Conclusions}\label{sec:conc}

So is this bad performance just due to the model being sub-par? 
Quite frankly, the method used to extract potential defaults could be much better as it is sensitive the resolution of the image.
This sensitivity is mostly due to the fact that every potential defect needs to be the same size to work on with the model.
This causes images of higher resolution to have the defect being cropped, 
thus making it harder for the model to both train and recognize it.
Inversly, images of low resolution may have defects that are too small and may include noise that distracts the model.
The method also works under the assumption that defects are often near edges detectable by canny edge detection, 
but that method has its limits and affects the potential defect extracted from an image.
The dataset used to train the model only contained a bit over 400 images, 
which isn't large and limits the ``bounds'' of the model so that it will have more trouble on a new image.
This is somewhat mitigated by data augmentation, 
but that method only goes so far as it modifies the current data and does not introduce new ``clues'' for the model to use.

Would this model be useful for the target audience?
In this state, not really.
But it is a good fondation that can be built upon by giving it more data and making it less sensitive to the original image resolution.
There were not obvious signs of overfitting in the model, 
so it is possible that more epochs will give a better accuracy,
at the cost of longer training.
The detection of potential defects can also be updated to either be more sensitive or be able to mask off parts of the image that isn't a potential defect.
This could be done by using a filter to put a strong blur on the area that is definitely not part of the defect so that the model will be less distracted.

Overall, this was an insightful dive into finding out what it takes to find defects on a road through the usage of edge detection and machine learning.
This is a rabbit hole of endless optimization but this just went through a very naive approach to solving a very complex problem that has very real consequences.

\appendix

\section{Sample images used in training the model}\label{app:train_data}

\subsection{Non defects}
\includegraphics{rd1_0.jpg}
\includegraphics{rd2_9.jpg}

\subsection{Cracks}
\includegraphics{rd1_3.jpg}
\includegraphics{rd2_2.jpg}

\subsection{Potholes}
\includegraphics{rd2_5.jpg}
\includegraphics{rd3_9.jpg}

\section{Model training plot}\label{app:model_plot}

\includegraphics{model_plot.png}

\section{Sample resulting images}\label{app:result_image}

\includegraphics{result_1.png}

\includegraphics{result_2.png}

\includegraphics{result_3.png}

\includegraphics{result_4.png}

\end{document}

% ----------